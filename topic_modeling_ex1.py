# -*- coding: utf-8 -*-
"""Topic_modeling_ex1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13YND_PtRPD8oWvVEbjyPaGNrFG6F0yD3
"""

#import packages
import requests
from bs4 import BeautifulSoup
import pandas as pd
import nltk
nltk.download('punkt')
import matplotlib.pyplot as plt
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
from gensim import models, corpora
from gensim.models import CoherenceModel

#make a request
data1=requests.get("https://en.wikipedia.org/wiki/Telecommunications")
data2=requests.get("https://en.wikipedia.org/wiki/Telecommunications_in_India")
data3=requests.get("https://community.data.gov.in/amount-deposited-by-private-telecom-companies-as-part-of-licensing-agreement-as-on-28th-feb-2020/")

#html format of the webpage
soup1=BeautifulSoup(data1.content,'html.parser')
soup2=BeautifulSoup(data2.content,'html.parser')
soup3=BeautifulSoup(data3.content,'html.parser')

#webpage1
print(soup1)

#webpage2
print(soup2)

#webpage3
print(soup3)

#webpage1 (paragraph)
para1=soup1.find_all('p')
for p1 in para1:
  print(p1.get_text())

para2=soup2.find_all('p')
for p2 in para2:
  print(p2.get_text())

para3=soup3.find_all('p')
for p3 in para3:
  print(p3.get_text())

text1=[p.text for p in para1]
text2=[p.text for p in para2]
text3=[p.text for p in para3]
df1=pd.DataFrame({"text" :text1})
df2=pd.DataFrame({"text" :text2})
df3=pd.DataFrame({"text" :text3})

print(df1,df2,df3)

new_data=pd.concat([df1,df2,df3])
print(new_data)

new_data.shape

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

#pre processing
import re
new_data['text'] = new_data['text'].apply(lambda x: re.sub(r'[^\w\s]', '', x))
new_data['text'] = new_data['text'].apply(lambda x: re.sub(r'\d+', '', x))
new_data['text'] = new_data['text'].apply(lambda x: re.sub(r'http\S+', '', x))
new_data['text'] = new_data['text'].str.lower()
new_data.head()

stop_words = set(stopwords.words('english'))

df = pd.concat([df1, df2, df3], ignore_index=True)
df['text_tokens']= df['text'].apply(word_tokenize)
direct=df['text_tokens']
df = df['text_tokens'].apply(lambda x: [word for word in x if word not in stop_words])

print(df.head())

import gensim.corpora as corpora
# Create Dictionary
id2word = corpora.Dictionary(direct)
# Create Corpus
texts = df
# Term Document Frequency
corpus = [id2word.doc2bow(text) for text in texts]
# View
print(corpus[:1][0][:30])

def calculate_coherence_score(corpus, id2word , k, texts):
    lda_model = models.LdaModel(corpus, num_topics=k, id2word=id2word)
    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word , coherence='c_v')
    return coherence_model_lda.get_coherence()

# Define the range for the number of topics
min_topics = 2
max_topics = 10
step_size = 1
topics_range = range(min_topics, max_topics + 1, step_size)

# List to store coherence scores
coherence_scores = []

# Iterate over the number of topics
for k in topics_range:
    # Train the LDA model
    lda_model = models.LdaModel(corpus, num_topics=k, id2word=id2word, passes=10, iterations=100)

    # Calculate coherence score
    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')
    coherence_score = coherence_model_lda.get_coherence()
    coherence_scores.append(coherence_score)

# Plotting the coherence scores
plt.figure(figsize=(12, 8))
plt.plot(topics_range, coherence_scores, marker='o', linestyle='-', color='b', markersize=8, linewidth=2)
plt.xlabel("Number of Topics", fontsize=14)
plt.ylabel("Coherence Score", fontsize=14)
plt.title("Coherence Score vs. Number of Topics", fontsize=16, fontweight='bold')
plt.xticks(topics_range, fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.axhline(y=max(coherence_scores), color='r', linestyle='--', linewidth=1.5)
plt.axvline(x=topics_range[coherence_scores.index(max(coherence_scores))], color='r', linestyle='--', linewidth=1.5)
plt.annotate(f'Max Coherence: {max(coherence_scores):.4f}',
             xy=(topics_range[coherence_scores.index(max(coherence_scores))], max(coherence_scores)),
             xytext=(topics_range[coherence_scores.index(max(coherence_scores))] + 0.5, max(coherence_scores) + 0.02),
             arrowprops=dict(facecolor='black', shrink=0.05),
             fontsize=12, color='red')
plt.tight_layout()
plt.show()

from pprint import pprint
import gensim
num_topics = 5

lda_model = gensim.models.LdaMulticore(corpus=corpus,
                                       id2word=id2word,
                                       num_topics=num_topics)

pprint(lda_model.print_topics())
doc_lda = lda_model[corpus]

#word cloud
#Topic 1
from wordcloud import WordCloud
long_string = ','.join(list(df1['text'].values))
wordcloud = WordCloud(background_color="white", max_words=5000, contour_width=3, contour_color='steelblue')
wordcloud.generate(long_string)
wordcloud.to_image()

#word cloud
#Topic 2
from wordcloud import WordCloud
long_string = ','.join(list(df2['text'].values))
wordcloud = WordCloud(background_color="white", max_words=5000, contour_width=3, contour_color='steelblue')
wordcloud.generate(long_string)
wordcloud.to_image()

#word cloud
#Topic 3
from wordcloud import WordCloud
long_string = ','.join(list(df3['text'].values))
wordcloud = WordCloud(background_color="white", max_words=5000, contour_width=3, contour_color='steelblue')
wordcloud.generate(long_string)
wordcloud.to_image()